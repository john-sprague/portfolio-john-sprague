
# Table of contents
- [CRDTs (Conflict-Free Replicated Data Types)](#crdts-conflict-free-replicated-data-types)
- [Detailed Breakdown of SQL Normalization Levels](#detailed-breakdown-of-sql-normalization-levels)
- [SQL ACID Transactions:  A Detailed Breakdown](#sql-acid-transactions-a-detailed-breakdown)
- [Understanding Quadtrees: A Detailed Breakdown](#understanding-quadtrees-a-detailed-breakdown)
- [Key Takeaways: GeoHashes vs. QuadTrees](#key-takeaways-geohashes-vs-quadtrees);
- [Sharding + Scatter-Gather for Scalable Distributed Systems](#sharding-scatter-gather-for-scalable-distributed-systems)
- [Sharding 101: The Essentials](#sharding-101-the-essentials)
- [Key Features and Reasons to Use a Message Queue in System Design](#key-features-and-reasons-to-use-a-message-queue-in-system-design)
- [Common approaches for distributed unique IDs](#common-approaches-for-distributed-uniqued-ids)
- [Distributed unique ID generators](#distributed-unique-id-generators)
- [Key Takeaways for Twitter‚Äôs Snowflake ID Generation Approach](#key-takeaways-for-twitters-snowflake-id-generation-approach)

# Intro: Always do two things in system design. 

1. **Connect the dots** 
- If i know how to design yelp, then I know how to design tinder, and how is tinder different then yelp? 

2. Check out the **tech blogs** for the actually companies to figure out what they did.

-- 


# CRDTs (Conflict-Free Replicated Data Types) 
CRDTs (Conflict-Free Replicated Data Types) are data structures designed for distributed systems that ensure eventual consistency without requiring complex synchronization mechanisms like locks or consensus protocols. They are particularly useful when multiple nodes update shared data independently.

### üî• **The 20% of CRDT Concepts That Deliver 80% of the Results**
1. **Eventual Consistency** ‚Äì CRDTs ensure all replicas reach the same state without coordination.
2. **Types of CRDTs**:
   - **State-based (Convergent Replicated Data Type, CvRDT)** ‚Äì Merge full state.
   - **Operation-based (Commutative Replicated Data Type, CmRDT)** ‚Äì Merge only updates.
3. **Monotonicity** ‚Äì Updates always grow in a way that prevents conflicts.
4. **Idempotency** ‚Äì Applying the same update multiple times results in the same state.
5. **Commutativity** ‚Äì Order of operations doesn‚Äôt matter.
6. **Merging Logic** ‚Äì Each CRDT has a defined way to merge changes deterministically.

## üèóÔ∏è **Building a Distributed Counter with CRDTs**
A counter is a simple but powerful use case for CRDTs, such as a **G-Counter (Grow-only Counter)** or **PN-Counter (Positive-Negative Counter).** 

### üîπ **1. Choose the Right CRDT**
For a distributed counter:
- **G-Counter**: Supports only **increments** (e.g., likes on a post).
- **PN-Counter**: Supports **increments and decrements** (e.g., upvotes/downvotes).

### üîπ **2. Implement a G-Counter**
A **G-Counter** maintains a per-node count and merges by taking the max value from each node.

#### **üìå Basic Steps:**
1. **Each node keeps its own local count.**
2. **When updating, it increments only its own count.**
3. **When merging, it takes the max value for each node.**

#### **üöÄ G-Counter Implementation in Python**
```javascript
class GCounter {
    constructor(nodeId) {
        this.nodeId = nodeId; // Unique identifier for the node
        this.counts = {}; // Stores per-node counts
    }

    // Increment the counter for the current node
    increment(amount = 1) {
        if (!this.counts[this.nodeId]) {
            this.counts[this.nodeId] = 0;
        }
        this.counts[this.nodeId] += amount;
    }

    // Merge another GCounter into this one
    merge(otherCounter) {
        for (const [node, value] of Object.entries(otherCounter.counts)) {
            if (this.counts[node]) {
                this.counts[node] = Math.max(this.counts[node], value);
            } else {
                this.counts[node] = value;
            }
        }
    }

    // Get the total value of the counter
    value() {
        return Object.values(this.counts).reduce((sum, val) => sum + val, 0);
    }
}

// Example usage:
const node1 = new GCounter("A");
const node2 = new GCounter("B");

node1.increment(3); // Node A increments by 3
node2.increment(2); // Node B increments by 2

// Nodes sync (merge)
node1.merge(node2);
node2.merge(node1);

console.log(node1.value()); // Output: 5
console.log(node2.value()); // Output: 5
```

### üîπ **3. Implement a PN-Counter**
A **PN-Counter** consists of two G-Counters:  
- **One for increments (P)**  
- **One for decrements (N)**  

The final value is `P - N`.

#### **üöÄ PN-Counter Implementation**
```javascript
class PNCounter {
    constructor(nodeId) {
        this.nodeId = nodeId;
        this.positive = new GCounter(nodeId);
        this.negative = new GCounter(nodeId);
    }

    increment(amount = 1) {
        this.positive.increment(amount);
    }

    decrement(amount = 1) {
        this.negative.increment(amount);
    }

    merge(otherCounter) {
        this.positive.merge(otherCounter.positive);
        this.negative.merge(otherCounter.negative);
    }

    value() {
        return this.positive.value() - this.negative.value();
    }
}

// Example usage:
const node1 = new PNCounter("A");
const node2 = new PNCounter("B");

node1.increment(5);
node2.increment(3);
node1.decrement(2);

// Merge the two nodes
node1.merge(node2);
node2.merge(node1);

console.log(node1.value()); // Output: 6 (5 + 3 - 2)
console.log(node2.value()); // Output: 6
```

---

## üì° **Integrating into a Distributed System**
Now that we have a CRDT counter, here‚Äôs how to use it in a real-world system:

### üîπ **1. Use CRDTs in a Distributed Database**
Many databases like **Riak, Redis (CRDT module), and AntidoteDB** support CRDTs natively.

### üîπ **2. Sync Updates Efficiently**
- **Peer-to-peer (Gossip Protocol)**: Nodes periodically exchange updates.
- **Event Sourcing**: Store operations in a log, replay them to reconstruct state.
- **Pub/Sub Model**: Use Kafka or RabbitMQ to broadcast updates.

- **Peer-to-Peer (Gossip Protocol) replication across CRDT replicas**
The internal implementation of CRDT is independent of the underlying network layer. For example, the communication layer can use gossip protocol for an efficient replication across CRDT replicas. The CRDT replication exchanges not only the data but also the operations performed on the data including their ordering and causality. The merging technique in CRDT will execute the received operations on the data. The following are the benefits of using CRDT to build the distributed counter.

offers local latency on read and write operations through multi-leader replication
enables automatic and deterministic conflict resolution
tolerant to network partitions
allow concurrent count updates without coordination between replica nodes
achieves eventual consistency through asynchronous data updates

### üîπ **3. Handle Network Partitions Gracefully**
CRDTs guarantee **eventual consistency**, meaning updates will propagate and merge automatically once network partitions heal.

---

## üöÄ **Key Takeaways**
‚úÖ **CRDTs eliminate conflicts in distributed systems.**  
‚úÖ **G-Counter for increments; PN-Counter for inc/dec.**  
‚úÖ **Use "merge by max" logic to ensure convergence.**  
‚úÖ **Ideal for counters, collaborative docs, and shopping carts.**  
‚úÖ **Integrate via gossip, event sourcing, or pub/sub for real-world use.**  

Want to go deeper? Try **Delta CRDTs** for efficiency or explore **LWW-Registers (Last Write Wins) for timestamped values.**

![alt text](image.png)

# Detailed Breakdown of SQL Normalization Levels

**Normalization** is the process of organizing a database to reduce redundancy and improve data integrity. It involves dividing a database into smaller, more manageable tables and defining relationships between them.  

Here‚Äôs a simple breakdown of each **normal form (NF):**  

#### **First Normal Form (1NF) ‚Äì Atomicity**  
‚úÖ Each column contains only atomic (indivisible) values.  
‚úÖ No repeating groups or arrays in a single row.  
‚úÖ Each row must be unique 
‚úÖ The order of columns and the order of the rows are not significant 

**Example (Before 1NF - Bad Table Design)**  
| OrderID | Customer | Products Purchased  |  
|---------|---------|---------------------|  
| 101     | Alice   | Apples, Bananas     |  
| 102     | Bob     | Oranges, Apples     |  

**Problem:** The "Products Purchased" column has multiple values in a single cell.  

**After 1NF - Good Table Design**  
| OrderID | Customer | Product   |  
|---------|---------|---------|  
| 101     | Alice   | Apples   |  
| 101     | Alice   | Bananas  |  
| 102     | Bob     | Oranges  |  
| 102     | Bob     | Apples   |  

---

#### **Second Normal Form (2NF) ‚Äì No Partial Dependencies**  
‚úÖ 1NF is satisfied.  
‚úÖ Every non-key column must depend on the whole primary key, not just part of it.  

**Example (Before 2NF - Bad Table Design)**  
| OrderID | Customer | Product  | Customer Address  |  
|---------|---------|---------|-----------------|  
| 101     | Alice   | Apples   | 123 Green St   |  
| 102     | Bob     | Oranges  | 456 Blue St    |  

**Problem:** The **Customer Address** only depends on "Customer" but not the whole "OrderID + Product" composite key.  

**After 2NF - Good Table Design (Splitting into Two Tables)**  
‚úÖ **Orders Table**  
| OrderID | CustomerID | Product  |  
|---------|-----------|---------|  
| 101     | 1         | Apples  |  
| 102     | 2         | Oranges |  

‚úÖ **Customers Table**  
| CustomerID | Customer Name | Address        |  
|-----------|--------------|--------------|  
| 1         | Alice        | 123 Green St  |  
| 2         | Bob          | 456 Blue St   |  

---

#### **Third Normal Form (3NF) ‚Äì No Transitive Dependencies**  
‚úÖ 2NF is satisfied.  
‚úÖ No non-key column should depend on another non-key column.  

**Example (Before 3NF - Bad Table Design)**  
| OrderID | Product  | Supplier Name | Supplier Address  |  
|---------|---------|--------------|-----------------|  
| 101     | Apples  | Fresh Farms  | 789 Orchard Rd  |  
| 102     | Oranges | Citrus Co.   | 456 Orange St   |  

**Problem:** "Supplier Address" depends on "Supplier Name," not directly on "OrderID."  

**After 3NF - Good Table Design (Splitting into Two Tables)**  
‚úÖ **Orders Table**  
| OrderID | Product  | SupplierID |  
|---------|---------|-----------|  
| 101     | Apples  | 1         |  
| 102     | Oranges | 2         |  

‚úÖ **Suppliers Table**  
| SupplierID | Supplier Name | Supplier Address  |  
|-----------|--------------|-----------------|  
| 1         | Fresh Farms  | 789 Orchard Rd  |  
| 2         | Citrus Co.   | 456 Orange St   |  

---

# **Detailed Breakdown of SQL Primary Keys & Foreign Keys**  

In relational databases, **Primary Keys (PK)** and **Foreign Keys (FK)** play a crucial role in maintaining data integrity and defining relationships between tables.  

---

### **üîë Primary Key (PK)**
### **Definition**  
A **Primary Key** is a column (or a set of columns) that uniquely identifies each row in a table.  

### **Key Characteristics**  
‚úÖ **Unique** ‚Äì No two rows can have the same primary key value.  
‚úÖ **Non-null** ‚Äì A primary key cannot contain NULL values.  
‚úÖ **Immutable** ‚Äì Once assigned, primary key values should not change.  
‚úÖ **Minimal** ‚Äì It contains only the necessary columns to uniquely identify a row.  

### **Example**  
#### **Customers Table (With Primary Key)**  
| CustomerID (PK) | Name  | Email           |  
|----------------|-------|----------------|  
| 1             | Alice | alice@email.com |  
| 2             | Bob   | bob@email.com   |  

Here, `CustomerID` is the **Primary Key** because it uniquely identifies each customer.  

### **Composite Primary Key**  
A **Composite Primary Key** consists of **two or more columns** that together form a unique identifier.  

#### **Example: Order Details Table (With Composite PK)**  
| OrderID (PK) | ProductID (PK) | Quantity |  
|-------------|--------------|----------|  
| 101         | A1           | 2        |  
| 101         | B3           | 5        |  
| 102         | A1           | 3        |  

Here, the **combination** of `OrderID` and `ProductID` ensures uniqueness.

---

## **üîó Foreign Key (FK)**
### **Definition**  
A **Foreign Key** is a column (or a set of columns) that **references a Primary Key** in another table. It establishes a relationship between tables, enforcing referential integrity.  

### **Key Characteristics**  
‚úÖ **References a Primary Key** in another table.  
‚úÖ **Maintains Data Integrity** ‚Äì Prevents invalid data entry.  
‚úÖ **Supports Relationships** ‚Äì Enables One-to-Many or Many-to-Many relationships.  
‚úÖ **Can Contain NULLs** if the relationship is optional.  

### **Example: Orders and Customers Relationship**  
#### **Customers Table (With Primary Key)**  
| CustomerID (PK) | Name  | Email           |  
|----------------|-------|----------------|  
| 1             | Alice | alice@email.com |  
| 2             | Bob   | bob@email.com   |  

#### **Orders Table (With Foreign Key)**  
| OrderID (PK) | CustomerID (FK) | OrderDate  |  
|-------------|----------------|-----------|  
| 101         | 1              | 2024-02-01 |  
| 102         | 2              | 2024-02-05 |  
| 103         | 1              | 2024-02-10 |  

Here, `CustomerID` in the **Orders Table** is a **Foreign Key**, linking to the `CustomerID` in the **Customers Table**.

---

## **üîó Relationships Between Tables**
### **One-to-Many Relationship**  
- **Example:** One customer can place multiple orders.  
- **Implementation:** A **Foreign Key in the Orders Table** referencing the **Primary Key in the Customers Table**.  

### **Many-to-Many Relationship**  
- **Example:** Students can enroll in multiple courses, and each course can have multiple students.  
- **Implementation:** Use a **junction table** with Foreign Keys referencing both tables.  

#### **Example: Enrollment Table (Many-to-Many Relationship)**
| StudentID (FK) | CourseID (FK) | EnrollmentDate |  
|---------------|-------------|---------------|  
| 1            | 101         | 2024-01-15    |  
| 2            | 102         | 2024-01-16    |  
| 1            | 103         | 2024-01-17    |  

---

## **üîπ SQL Commands for Primary and Foreign Keys**
### **Creating a Table with a Primary Key**
```sql
CREATE TABLE Customers (
    CustomerID INT PRIMARY KEY,
    Name VARCHAR(100),
    Email VARCHAR(100) UNIQUE
);
```

### **Creating a Table with a Foreign Key**
```sql
CREATE TABLE Orders (
    OrderID INT PRIMARY KEY,
    CustomerID INT,
    OrderDate DATE,
    FOREIGN KEY (CustomerID) REFERENCES Customers(CustomerID)
);
```

### **Defining a Composite Primary Key**
```sql
CREATE TABLE OrderDetails (
    OrderID INT,
    ProductID INT,
    Quantity INT,
    PRIMARY KEY (OrderID, ProductID)
);
```

## SQL ACID Transactions: A Detailed Breakdown

In SQL databases, **ACID** properties ensure reliable processing of transactions. A **transaction** is a sequence of operations performed as a single logical unit of work. The **ACID principles** guarantee that even in case of failures, the database remains consistent and accurate.  

---

## **üî• What is ACID?**  
ACID stands for **Atomicity, Consistency, Isolation, and Durability**‚Äîfour key properties that ensure safe and reliable database transactions.  

### **1Ô∏è‚É£ Atomicity ‚Äì "All or Nothing"**  
‚úÖ Ensures that a transaction is **fully completed or fully rolled back**.  
‚úÖ If any part of the transaction fails, the entire transaction is undone.  

üîπ **Example:**  
Imagine transferring $100 from Alice‚Äôs account to Bob‚Äôs account:  

```sql
BEGIN TRANSACTION;
UPDATE Accounts SET Balance = Balance - 100 WHERE Name = 'Alice'; 
UPDATE Accounts SET Balance = Balance + 100 WHERE Name = 'Bob';
COMMIT;
```
- If the **first update succeeds** but the **second update fails**, the entire transaction is rolled back to prevent data inconsistency.  

üí° **Think of it like a flight booking:** If the payment fails, you don‚Äôt get a ticket.  

---

### **2Ô∏è‚É£ Consistency ‚Äì "Maintaining Valid Data"**  
‚úÖ Ensures that the database **moves from one valid state to another**.  
‚úÖ Prevents invalid data (e.g., negative balances) from being inserted.  

üîπ **Example:**  
A banking system should **never allow** an account balance to go negative. If a transaction would violate this rule, the system rejects it.  

```sql
BEGIN TRANSACTION;
UPDATE Accounts SET Balance = Balance - 500 WHERE Name = 'Charlie';
-- If Charlie has only $300, rollback the transaction
IF (SELECT Balance FROM Accounts WHERE Name = 'Charlie') < 0
   ROLLBACK;
ELSE
   COMMIT;
```

üí° **Think of it like a vending machine:** You must insert the correct amount of money before getting a product.  

---

### **3Ô∏è‚É£ Isolation ‚Äì "No Interference Between Transactions"**  
‚úÖ Ensures that concurrent transactions **don‚Äôt interfere** with each other.  
‚úÖ Prevents issues like **dirty reads**, **non-repeatable reads**, and **phantom reads**.  

üîπ **Example:**  
Two users simultaneously trying to buy the last concert ticket:  

```sql
BEGIN TRANSACTION;
SELECT Tickets_Available FROM Concerts WHERE Concert_ID = 1; 
-- If Tickets_Available > 0, proceed with the purchase
UPDATE Concerts SET Tickets_Available = Tickets_Available - 1 WHERE Concert_ID = 1;
COMMIT;
```
- Without isolation, **both users might see 1 available ticket** and purchase it, causing overselling.  

üí° **Think of it like online shopping:** If two people try to buy the last item, only one should succeed.  

üîπ **SQL Isolation Levels:**  
1. **Read Uncommitted** ‚Äì Allows dirty reads (least strict).  
2. **Read Committed** ‚Äì Prevents dirty reads but allows non-repeatable reads.  
3. **Repeatable Read** ‚Äì Prevents non-repeatable reads but allows phantom reads.  
4. **Serializable** ‚Äì The strictest level, fully isolates transactions.  

---

### **4Ô∏è‚É£ Durability ‚Äì "Data is Permanently Saved"**  
‚úÖ Once a transaction is committed, **it remains saved even if a system crash occurs**.  

üîπ **Example:**  
After a bank transfer, the system writes the final balance to disk before confirming the transaction:  

```sql
BEGIN TRANSACTION;
UPDATE Accounts SET Balance = Balance - 100 WHERE Name = 'David';
UPDATE Accounts SET Balance = Balance + 100 WHERE Name = 'Emma';
COMMIT; -- Ensures changes are stored permanently
```
- Even if the power goes out **right after COMMIT**, the changes remain safe.  

üí° **Think of it like writing a final exam:** Once you submit it, your answers are stored and can‚Äôt be changed.  

---

## Understanding Quadtrees: A Detailed Breakdown

A **quadtree** is a tree data structure used to divide a two-dimensional space into four quadrants (regions). It is widely used in **spatial indexing, computer graphics, image processing, GIS (Geographic Information Systems), and collision detection in games**.  

---

## **üü¢ What is a Quadtree?**  
A **quadtree** recursively divides a 2D space into four equal regions until each region contains a specific amount of data (or reaches a minimum size).  

### **Key Characteristics:**  
‚úÖ **Hierarchical Structure** ‚Äì Organizes data in levels of four children per node.  
‚úÖ **Adaptive Subdivision** ‚Äì Divides space only where needed.  
‚úÖ **Efficient for Sparse Data** ‚Äì Avoids unnecessary storage of empty regions.  
‚úÖ **Used for Spatial Partitioning** ‚Äì Helps in fast lookups, neighbor searches, and collision detection.  

---

## **üìå Types of Quadtrees**  

### **1Ô∏è‚É£ Point Quadtree**  
- Stores **points** in a 2D plane.  
- Used for nearest-neighbor searches and fast lookups.  

üîπ **Example:** Spatial indexing of objects in a game world.  

### **2Ô∏è‚É£ Region Quadtree**  
- Used for **images and spatial data**.  
- Each node represents a **region** of space, divided if necessary.  

üîπ **Example:** Image compression, where areas of the same color are grouped together.  

### **3Ô∏è‚É£ PR (Point Region) Quadtree**  
- Similar to **Point Quadtree**, but only stores **points at the leaves**.  
- Each node represents a **bounding region**.  

üîπ **Example:** Storing locations of objects in a **2D game**.  

### **4Ô∏è‚É£ MX (Matrix) Quadtree**  
- Used to store **gridded data** (e.g., pixelated images, terrain maps).  
- Each node represents a **fixed region** of the grid.  

üîπ **Example:** Image processing and compression.  

---

## **üìä Structure of a Quadtree**  
Each **node** in a quadtree has:  
1. A **bounding box** defining the region it covers.  
2. Up to **four children** (NE, NW, SE, SW) representing subdivided regions.  
3. A **threshold condition** to determine if it should be split further.  

---

## **üåç Example: A Simple Quadtree**  

Imagine a **2D game map** where objects (like trees and enemies) are stored in a quadtree for fast lookups.  

### **Step 1: Start with a region**  
A **512x512 map** with objects scattered across it.  

### **Step 2: Divide into Quadrants**  
- If a quadrant has **more than one object**, split it into four smaller quadrants.  
- Continue recursively until each quadrant contains **only one object or is empty**.  

### **Step 3: Store Objects in Leaves**  
The **final tree structure** represents a compressed spatial map, allowing fast searches for objects in any given area.  

---

## **üìù Quadtree Operations**  

### **‚úî Insertion**  
- **Find the correct quadrant** based on object position.  
- **Insert object** into that quadrant.  
- If a node exceeds the threshold, **subdivide** further.  

### **‚úî Search (Point Query)**  
- Start at the root and **traverse to the correct quadrant**.  
- If found, return the object; otherwise, return NULL.  

### **‚úî Deletion**  
- Locate the object, remove it, and **recombine empty quadrants** if needed.  

### **‚úî Range Query (Finding Objects in an Area)**  
- Traverse **only relevant branches** that intersect the search region.  
- Faster than scanning all objects in an unstructured list.  

---

## **üîß Code Example: Implementing a Simple Quadtree in Python**  

```javascript
class Quadtree {
    constructor(x, y, width, height, capacity = 1) {
        this.boundary = { x, y, width, height };
        this.capacity = capacity;
        this.points = [];
        this.divided = false;
    }

    subdivide() {
        const { x, y, width, height } = this.boundary;
        const halfWidth = width / 2;
        const halfHeight = height / 2;

        this.northeast = new Quadtree(x + halfWidth, y, halfWidth, halfHeight, this.capacity);
        this.northwest = new Quadtree(x, y, halfWidth, halfHeight, this.capacity);
        this.southeast = new Quadtree(x + halfWidth, y + halfHeight, halfWidth, halfHeight, this.capacity);
        this.southwest = new Quadtree(x, y + halfHeight, halfWidth, halfHeight, this.capacity);

        this.divided = true;
    }

    insert(point) {
        if (this.points.length < this.capacity) {
            this.points.push(point);
        } else {
            if (!this.divided) {
                this.subdivide();
            }
            this.northeast.insert(point);
            this.northwest.insert(point);
            this.southeast.insert(point);
            this.southwest.insert(point);
        }
    }
}

![alt text](image-1.png)

// Example Usage
const qt = new Quadtree(0, 0, 100, 100);
qt.insert([30, 40]);
qt.insert([60, 70]);
```
This simple **quadtree implementation** divides space and inserts points dynamically.

---

## **üÉè Flashcard Set for Studying Quadtrees**  

### **üÉè Flashcard 1**  
**Q:** What is a **quadtree**?  
**A:** A tree data structure that recursively divides 2D space into four quadrants.  

### **üÉè Flashcard 2**  
**Q:** What are the **four main types** of quadtrees?  
**A:** **Point Quadtree, Region Quadtree, PR Quadtree, MX Quadtree.**  

### **üÉè Flashcard 3**  
**Q:** What is a **Point Quadtree** used for?  
**A:** Storing and searching **points** in a 2D space.  

### **üÉè Flashcard 4**  
**Q:** What is the **main advantage** of quadtrees?  
**A:** They enable **fast spatial searches** and optimize memory usage by dividing space only where needed.  

### **üÉè Flashcard 5**  
**Q:** What happens when a quadtree node **exceeds its capacity**?  
**A:** It **subdivides** into four child quadrants.  

### **üÉè Flashcard 6**  
**Q:** What is a **Region Quadtree** used for?  
**A:** Representing images and large spatial data by grouping similar regions.  

### **üÉè Flashcard 7**  
**Q:** What is the **primary purpose** of a quadtree in **games**?  
**A:** Collision detection and fast object lookups in a **2D world**.  

### **üÉè Flashcard 8**  
**Q:** How does a **quadtree improve range queries**?  
**A:** By allowing searches to **skip irrelevant regions** instead of scanning all objects.  

### **üÉè Flashcard 9**  
**Q:** What operation recombines empty quadrants after removing objects?  
**A:** **Merging (or collapsing)** adjacent empty nodes.  

### **üÉè Flashcard 10**  
**Q:** Name a real-world application of quadtrees in **geographic systems (GIS).**  
**A:** **Storing and searching map data** for fast spatial lookups.  

---

# **Key Takeaways: GeoHashes vs. QuadTrees**  

Both **GeoHashes** and **QuadTrees** are spatial indexing techniques used for **efficient geospatial searching**, but they have different strengths and trade-offs.  

## **üìå GeoHashes**  
‚úÖ **What It Is:**  
- A **string-based** encoding system that recursively divides the world into grid-like regions.  
- Converts latitude/longitude into a **hash string**, where shorter hashes represent larger areas, and longer hashes represent smaller, more precise areas.  

‚úÖ **Key Properties:**  
- **Hierarchical**: Shorter GeoHashes cover larger areas, while longer ones refine the location.  
- **Prefix-based proximity**: Nearby locations often share common hash prefixes.  
- **Fixed grid size**: Divides space into **predefined rectangular regions**.  

‚úÖ **Advantages:**  
‚úî **Fast Lookups** ‚Äì GeoHashes can be used as **keys in a database** for quick searches.  
‚úî **Efficient for Proximity Searches** ‚Äì Nearby places often share hash prefixes.  
‚úî **Compact Storage** ‚Äì GeoHashes use short strings instead of floating-point numbers.  
‚úî **Works Well with Distributed Databases** ‚Äì Can be used for sharding.  

‚úÖ **Disadvantages:**  
‚ùå **Grid Distortion** ‚Äì GeoHashes use **rectangular grids**, which don‚Äôt align well with the Earth's curvature.  
‚ùå **Edge Cases** ‚Äì Queries across hash boundaries require multiple hash lookups.  
‚ùå **Fixed Partitioning** ‚Äì Cannot dynamically adjust to data density.  

‚úÖ **Best For:**  
- **Fast approximate search** in large-scale applications (e.g., **caching** & **database sharding**).  
- **Hash-based geospatial indexing** (e.g., **Redis, Elasticsearch, MongoDB**).  

---

## **üìå QuadTrees**  
‚úÖ **What It Is:**  
- A **tree-based** spatial partitioning structure that recursively divides the world into **four quadrants** at each level.  
- Each region is subdivided **only if needed**, making it more flexible than fixed grid systems like GeoHashes.  

‚úÖ **Key Properties:**  
- **Adaptive Resolution** ‚Äì More subdivisions in dense areas, fewer in sparse areas.  
- **Recursive Tree Structure** ‚Äì Each node has **four child nodes**, forming a hierarchy.  
- **Efficient Range Queries** ‚Äì Optimized for finding points in a given area.  

‚úÖ **Advantages:**  
‚úî **Better Space Adaptation** ‚Äì **Denser regions** get more refined subdivisions.  
‚úî **Efficient for Range Queries** ‚Äì Queries can traverse the tree to find all points in a bounding box.  
‚úî **No Grid Distortion** ‚Äì Works well across different regions.  

‚úÖ **Disadvantages:**  
‚ùå **More Complex Implementation** ‚Äì Requires a tree structure instead of simple hashes.  
‚ùå **Slower Lookups in Large Datasets** ‚Äì Compared to hash-based lookups.  
‚ùå **Storage Overhead** ‚Äì Each node in the tree consumes additional memory.  

‚úÖ **Best For:**  
- **Precise geospatial indexing** with **adaptive resolution** (e.g., **mapping applications, game engines**).  
- **Efficient range queries** in variable-density datasets.  

---

## **üöÄ Key Differences & Trade-offs**  
| Feature         | **GeoHashes** ‚úÖ | **QuadTrees** ‚úÖ |
|---------------|----------------|----------------|
| **Structure** | **Grid-based hashing** | **Tree-based partitioning** |
| **Spatial Adaptability** | ‚ùå Fixed partitions | ‚úÖ Dynamically subdivides dense areas |
| **Lookup Speed** | ‚úÖ Fast (simple hash lookup) | ‚ùå Slower (tree traversal) |
| **Proximity Queries** | ‚úÖ Good (shared hash prefixes) | ‚úÖ Better (adaptive resolution) |
| **Range Queries** | ‚ùå Requires multiple hash lookups | ‚úÖ Optimized for bounding box queries |
| **Edge Cases Handling** | ‚ùå Requires multiple GeoHashes for boundary cases | ‚úÖ Handles boundaries more naturally |
| **Implementation Complexity** | ‚úÖ Simple (just hashing) | ‚ùå More complex (tree structure) |
| **Storage Overhead** | ‚úÖ Low (compact string encoding) | ‚ùå Higher (tree nodes take space) |
| **Best Use Case** | **Fast approximate searches** (e.g., caching, distributed DBs) | **Precise spatial queries** (e.g., maps, games, GIS) |

---

## **üöÄ Which One Should You Use?**  
‚úÖ **GeoHashes** ‚Üí **If you need fast, approximate lookups** (e.g., caching, DB indexing).  
‚úÖ **QuadTrees** ‚Üí **If you need precise spatial queries** (e.g., detailed mapping, adaptive partitioning).  

For a **Yelp-like search service**, a **hybrid approach** is often best:  
- Use **GeoHashes for fast lookup** & database sharding.  
- Use **QuadTrees for refined spatial queries** in high-density areas.  

Would you like a deeper dive into how to implement these in a database? üöÄ

Absolutely! Scatter-Gather is a crucial pattern when working with **sharded** or **distributed systems**, especially in query execution. Let‚Äôs integrate it into the **80/20 rule** for sharding.

---

# Sharding 101: The Essentials
Sharding is the process of **splitting data** across multiple nodes (shards) to distribute load and increase scalability.

### üî• **The 20% That Delivers 80% of the Results**
1. **Choose the Right Sharding Strategy**
2. **Prevent Hotspots**
3. **Handle Rebalancing**
4. **Minimize Cross-Shard Queries**
5. **Ensure Fault Tolerance & Failover**

---

### 1Ô∏è‚É£ **Choose the Right Sharding Strategy**
The way you distribute data across shards impacts performance. Here are the three most common strategies:

### ‚úÖ **1. Range-Based Sharding**  
- **How it works**: Data is partitioned based on a range of values (e.g., `user_id 1-1M in shard A, 1M-2M in shard B`).
- **Best for**: Sequential or range-based queries (e.g., time-series data).
- **Pros**:
  - Fast range queries.
  - Easy to implement.
- **Cons**:
  - Can lead to hotspots if certain ranges are more popular.
  - Harder to balance load dynamically.

---

### ‚úÖ **2. Hash-Based Sharding**  
- **How it works**: Data is assigned to a shard using a hash function (e.g., `hash(user_id) % num_shards`).
- **Best for**: Evenly distributing data across shards (e.g., user profiles, orders).
- **Pros**:
  - Avoids hotspots (even load distribution).
  - Scales well for random-access queries.
- **Cons**:
  - Slower range queries since data is spread across shards.
  - Harder to rebalance when adding/removing shards.

---

### ‚úÖ **3. Directory-Based (Lookup Table) Sharding**  
- **How it works**: A central lookup table maps keys to shards dynamically.
- **Best for**: Cases where sharding logic is complex or changes frequently.
- **Pros**:
  - Fully flexible; you can move shards dynamically.
- **Cons**:
  - The lookup table becomes a **single point of failure**.
  - Requires an extra query to resolve the shard location.

---

### 2Ô∏è‚É£ **Prevent Hotspots**
Hotspots occur when some shards get significantly more load than others.

üîπ **Solution**:  
- If using **range-based sharding**, distribute load evenly (e.g., by sharding on time buckets instead of raw timestamps).
- If using **hash-based sharding**, ensure a good hash function to evenly distribute data.
- Use **consistent hashing** (e.g., **Ketama hashing**) to reduce impact when adding/removing shards.

---

### 3Ô∏è‚É£ **Handle Rebalancing (Adding/Removing Shards)**
When you add a new shard, you must redistribute data efficiently.

üîπ **Common Approaches**:
1. **Predefined Fixed Shards**: Plan ahead for extra empty shards, so adding a new one doesn‚Äôt require moving data.
2. **Consistent Hashing**: Minimizes data movement when increasing the number of shards.
3. **Automated Rebalancing**: Use tools like **Apache Kafka, Vitess, or DynamoDB** that support automatic rebalancing.

---

### 4Ô∏è‚É£ **Minimize Cross-Shard Queries**
Querying multiple shards slows down performance.

üîπ **How to optimize**:
- **Query Routing**: Use an index to send queries only to relevant shards.
- **Denormalization**: Store frequently joined data in the same shard.
- **Scatter-Gather**: If cross-shard queries are unavoidable, optimize the gather phase.

Example: If searching for a user‚Äôs posts, store **users and posts in the same shard** instead of querying multiple shards.

---

### 5Ô∏è‚É£ **Ensure Fault Tolerance & Failover**
Sharding introduces new failure points. If one shard goes down, part of your data is unavailable.

üîπ **Solutions**:
- Use **replication**: Each shard should have replicas.
- Implement **failover strategies**: If a shard fails, redirect queries to a replica.
- **Use a load balancer**: Distribute requests evenly across shards.

---

### üî• **80/20 Takeaways**
‚úÖ Pick a **sharding strategy** that fits your data & query patterns.  
‚úÖ Prevent **hotspots** to avoid overload on a single shard.  
‚úÖ Plan for **rebalancing** before you need it.  
‚úÖ Reduce **cross-shard queries** to improve performance.  
‚úÖ Use **replication & failover** to ensure high availability.  

---

# Sharding: Scatter Gather for Scalable Distributed Systems
Sharding distributes data, but Scatter-Gather **efficiently queries** that data across shards.

### üî• **The 20% That Delivers 80% of the Results**
1Ô∏è‚É£ **Sharding Strategies** (Hash, Range, Lookup Table)  
2Ô∏è‚É£ **Preventing Hotspots** (Load Balancing)  
3Ô∏è‚É£ **Handling Rebalancing** (Adding/Removing Shards)  
4Ô∏è‚É£ **Scatter-Gather for Query Execution**  
5Ô∏è‚É£ **Ensuring Fault Tolerance & Failover**  

---

### **Scatter-Gather for Query Execution**
Sharding improves scalability, but querying across shards can be expensive. **Scatter-Gather** solves this problem.

### ‚úÖ **What is Scatter-Gather?**
It's a distributed query pattern where:
1. The request is **scattered** to all relevant shards.
2. Each shard **processes** the request independently.
3. The results are **gathered** and combined.

### ‚úÖ **Best Use Cases**
- **Search Engines** (Google, Elasticsearch)  
- **Distributed Databases** (MongoDB, Cassandra, DynamoDB)  
- **Analytics Queries** (Summing data across shards)  

---

### üî• **Optimizing Scatter-Gather for Performance**
üîπ **Query Routing**: Send queries only to relevant shards (avoid unnecessary work).  
üîπ **Parallel Execution**: Run queries in parallel across shards to reduce latency.  
üîπ **Pre-Aggregation**: Process data at the shard level before merging results.  
üîπ **Load Balancing**: Ensure no single shard gets overloaded.  

---

### ‚úÖ **Example: Scatter-Gather in Action**
Imagine you have a **sharded e-commerce database** where each shard stores orders based on `user_id` (hash-based sharding).  
You need to find the **total revenue for the last 30 days**.

1Ô∏è‚É£ **Scatter Phase**  
- The query (`SUM(order_amount) WHERE date > last 30 days`) is sent to **all shards**.  

2Ô∏è‚É£ **Shard Processing**  
- Each shard **calculates a local sum** of `order_amount`.  

3Ô∏è‚É£ **Gather Phase**  
- The results are returned to an **aggregator**, which sums up the totals from all shards.  

üéØ **Optimization**: If you store **pre-aggregated totals per shard**, you can query **only the relevant ones**, reducing scatter overhead.

---

### üî• **80/20 Takeaways**
‚úÖ **Sharding** distributes data; **Scatter-Gather** efficiently queries it.  
‚úÖ Route queries **only to necessary shards** to reduce overhead.  
‚úÖ Use **parallel execution** to improve speed.  
‚úÖ **Pre-aggregate** data to avoid expensive scatter-gather operations.  
‚úÖ Implement **failover and replication** for reliability.  

# Key Features and Reasons to Use a Message Queue in System Design

A **message queue** is a key component in **distributed systems**, enabling asynchronous communication between services. It decouples producers (senders) from consumers (receivers), allowing for **scalability, reliability, and resilience** in system architectures.

---

## **üîë Key Features of a Message Queue**
1. **Asynchronous Processing**  
   - Producers send messages without waiting for consumers to process them.  
   - Helps in handling time-consuming tasks without blocking requests.  

2. **Decoupling of Services**  
   - Enables microservices to interact without direct dependencies.  
   - Improves maintainability and scalability by allowing independent service deployment.  

3. **Guaranteed Delivery (Reliability)**  
   - Ensures messages are **persisted** and **retried** if delivery fails.  
   - Features like **acknowledgments (ACKs), message persistence, and dead-letter queues (DLQ)** help prevent message loss.  

4. **Load Balancing**  
   - Distributes messages across multiple consumers to scale processing dynamically.  
   - Example: Multiple worker nodes can consume messages from a single queue to parallelize tasks.  

5. **Fault Tolerance & High Availability**  
   - Messages can be **stored and replayed** even if a consumer or producer crashes.  
   - Replication across nodes ensures **zero data loss** in case of failures.  

6. **Rate Limiting & Throttling**  
   - Protects downstream services from overload by controlling the message consumption rate.  
   - Useful in API rate limiting and managing sudden traffic spikes.  

7. **FIFO & Message Ordering (If Needed)**  
   - Some message queues (like Kafka) guarantee strict **ordering** within partitions.  
   - Ensures correct sequence execution in workflows like financial transactions.  

8. **Event-Driven Architecture Support**  
   - Helps in **real-time event streaming** (e.g., user activity tracking, notifications, log aggregation).  
   - Enables **pub-sub** models where multiple consumers receive the same event.  

9. **Transactional Messaging (Exactly-Once Processing)**  
   - Ensures messages are **processed once and only once**, preventing duplication.  
   - Useful in financial systems and critical workflows.  

---

## **üöÄ Why Use a Message Queue?**
### ‚úÖ **1. Scalability**  
- Allows horizontal scaling by distributing messages across multiple consumers.  
- Example: **E-commerce order processing** scales during peak traffic (e.g., Black Friday sales).  

### ‚úÖ **2. Fault Tolerance & Resilience**  
- Prevents data loss by persisting messages even if a service crashes.  
- Example: A **banking transaction system** uses queues to ensure transaction logs are reliably stored.  

### ‚úÖ **3. Microservices & Decoupling**  
- Services communicate asynchronously without direct dependencies.  
- Example: A **payment service** can process transactions without blocking an **order service**.  

### ‚úÖ **4. Performance Optimization**  
- Offloads heavy tasks to background workers, improving system response times.  
- Example: **Image processing in social media apps** (upload first, process later).  

### ‚úÖ **5. Buffering & Traffic Spikes Handling**  
- Absorbs high traffic loads and prevents service crashes.  
- Example: **Ride-hailing apps** handle surge requests by queuing ride assignments.  

---

## **üìå Common Message Queue Technologies**
- **RabbitMQ** ‚Üí Lightweight, great for transactional messaging.  
- **Apache Kafka** ‚Üí High-throughput, real-time event streaming.  
- **Amazon SQS** ‚Üí Fully managed, easy to scale.  
- **Google Pub/Sub** ‚Üí Cloud-native, event-driven messaging.  

# Common approaches for distributed unique IDs
In a **distributed system**, generating **unique IDs** is critical for ensuring consistency across multiple nodes. Here are some common approaches:

---

## **1. UUID (Universally Unique Identifier)**
**Example in JavaScript:**
```javascript
const { v4: uuidv4 } = require('uuid');
console.log(uuidv4()); // e.g., "550e8400-e29b-41d4-a716-446655440000"
```
‚úÖ **Pros**:
- Globally unique without coordination.
- Simple to implement.

‚ùå **Cons**:
- **Long (128-bit)** ‚Üí Less efficient for indexing.
- **Not time-ordered**, which can impact performance in databases.

---

## **2. Snowflake IDs (Time-Ordered, Scalable)**
This is Twitter‚Äôs approach (see previous message).  
‚úÖ **Pros**:
- **Compact (64-bit)** & time-ordered.
- Supports **sharding** (machine IDs).
- High throughput (~4096 IDs/ms per node).

‚ùå **Cons**:
- Requires **clock synchronization** across nodes.

---

## **3. Database Auto-Increment + Sharding**
Each database instance is assigned a **range of IDs**:
- **DB1** ‚Üí IDs: `1, 4, 7...`
- **DB2** ‚Üí IDs: `2, 5, 8...`
- **DB3** ‚Üí IDs: `3, 6, 9...`

‚úÖ **Pros**:
- Easy to implement with databases.

‚ùå **Cons**:
- **Requires coordination** ‚Üí Risk of ID collisions.
- **Not highly scalable** for distributed environments.

---

## **4. Hash-Based IDs (e.g., MD5, SHA-1, SHA-256)**
Hash a combination of machine ID, timestamp, and random value:
```javascript
const crypto = require('crypto');
const uniqueId = crypto.createHash('sha256').update(Date.now().toString()).digest('hex');
console.log(uniqueId);
```
‚úÖ **Pros**:
- **Deterministic and unique**.
- No need for a centralized generator.

‚ùå **Cons**:
- **Long (e.g., 256-bit for SHA-256)**.
- Not naturally **time-ordered**.

---

## **5. Nano ID (Compact, Collision-Resistant)**
**Example:**
```javascript
const { nanoid } = require('nanoid');
console.log(nanoid()); // e.g., "V1StGXR8_Z5jdHi6B-myT"
```
‚úÖ **Pros**:
- **Short (~21 characters)**.
- Higher **collision resistance** than UUIDs.

‚ùå **Cons**:
- Not time-ordered.

---

## **6. Zookeeper/Etlcd Sequence Nodes**
Distributed coordination using Zookeeper or etcd, where each node requests a **sequential number**.
‚úÖ **Pros**:
- **Strict ordering** across multiple nodes.

‚ùå **Cons**:
- **Network latency & overhead**.
- Single point of failure if not managed properly.

---

### **TL;DR:**
- **For databases ‚Üí Auto-increment + sharding** (simple but needs coordination).
- **For high-performance systems ‚Üí Snowflake IDs** (compact, time-ordered).
- **For uniqueness without coordination ‚Üí UUIDs or Nano IDs**.
- **For strict ordering ‚Üí Zookeeper/etcd sequence numbers**.

# Distributed unique ID generators
A **distributed unique ID generator** is crucial in systems where multiple nodes operate independently but still need **globally unique, scalable, and ordered IDs**. Here are some key **use cases**:

---

### **1. Large-Scale Databases (Sharded or Distributed)**
- **Use Case**: Assigning primary keys across **multiple database nodes** without conflicts.
- **Example**: A **sharded MySQL or NoSQL database (e.g., MongoDB, Cassandra)** where IDs must be unique across all shards.

---

### **2. Distributed Logging & Monitoring**
- **Use Case**: Generating unique request IDs for **tracing logs across microservices**.
- **Example**: In **distributed tracing (e.g., OpenTelemetry, Jaeger, Zipkin)**, a **correlation ID** helps track a request through multiple services.

---

### **3. Message Queues & Event Processing**
- **Use Case**: Assigning unique IDs to **messages/events** to prevent duplicates and ensure ordering.
- **Example**: Kafka, RabbitMQ, and AWS Kinesis use **unique message IDs** for deduplication and ordering.

---

### **4. Microservices Communication**
- **Use Case**: Generating unique IDs for API requests between microservices.
- **Example**: A **user request flows through multiple microservices**, and each service logs the same unique ID for tracking.

---

### **5. E-commerce Transactions & Order IDs**
- **Use Case**: Ensuring unique **order IDs** across multiple payment gateways and warehouses.
- **Example**: A global e-commerce site needs unique IDs for orders across **multiple regions and warehouses**.

---

### **6. Social Media & Content Platforms**
- **Use Case**: Generating unique IDs for **posts, comments, likes, and messages**.
- **Example**: Twitter uses **Snowflake IDs** for tweets, ensuring each tweet has a **time-ordered unique ID**.

---

### **7. Blockchain & Cryptocurrency Transactions**
- **Use Case**: Assigning unique IDs to **blocks and transactions** in a distributed ledger.
- **Example**: **Bitcoin, Ethereum** use unique hashes, but systems managing transactions may use **Snowflake-like IDs**.

---

### **8. IoT (Internet of Things)**
- **Use Case**: Assigning unique IDs to **millions of IoT devices and sensor data**.
- **Example**: Smart home devices or industrial sensors generate **real-time logs**, requiring unique and time-ordered IDs.

---

### **9. AI/ML Data Pipelines**
- **Use Case**: Labeling training data uniquely across **distributed ML training nodes**.
- **Example**: A machine learning pipeline assigns **unique IDs** to each image in a dataset for processing.

---

### **10. Financial Services (Banking, Trading, Payments)**
- **Use Case**: Generating unique IDs for **trades, transactions, and payments**.
- **Example**: High-frequency trading systems require **ultra-fast unique IDs** for every trade executed.

---

### **TL;DR (80/20 Rule)** üöÄ  
If you need **scalable, time-ordered, unique IDs**, a **distributed unique ID generator** is critical for:
1. **Databases & sharding** (Primary keys)
2. **Logging & tracing** (Request correlation)
3. **Message queues & events** (Event deduplication)
4. **E-commerce & payments** (Order IDs)
5. **Social media & real-time apps** (Tweet/Post IDs)
6. **Blockchain & IoT** (Transaction & device tracking)

# Key Takeaways for Twitter‚Äôs Snowflake ID Generation Approach
Twitter‚Äôs **Snowflake** is a **distributed, time-ordered unique ID generation system** designed to create unique 64-bit IDs efficiently across multiple nodes. It solves the problem of generating **globally unique**, **sortable**, and **highly available** IDs without requiring a centralized database.

#### **1. Structure of a Snowflake ID (64 bits total)**
| Bits | Field Name       | Description |
|------|----------------|-------------|
| 1    | **Sign Bit**    | Always `0` (ensures positive numbers) |
| 41   | **Timestamp**   | Milliseconds since a custom epoch (ensures time-ordering) |
| 10   | **Machine ID**  | Unique identifier for the node generating the ID |
| 12   | **Sequence**    | Incrementing counter for IDs generated within the same millisecond |

#### **2. Core Benefits (The 80/20)**
- **Scalability** ‚Äì Distributed generation without coordination.
- **Uniqueness** ‚Äì Ensures no duplicate IDs across multiple nodes.
- **Time-ordered** ‚Äì IDs increase monotonically, useful for indexing.
- **High Throughput** ‚Äì Generates millions of IDs per second.
- **No Database Bottleneck** ‚Äì Avoids reliance on a centralized ID generator.

#### **3. The 20% That Delivers 80% of the Value**
- **Use timestamps for order** ‚Äì The **41-bit timestamp** ensures time-based sorting.
- **Decentralized ID generation** ‚Äì Each machine can generate its own IDs with a **10-bit node ID**.
- **Handle high throughput with a 12-bit counter** ‚Äì Supports **4096 unique IDs per millisecond per node**.
- **Avoid clock drift issues** ‚Äì If the system clock moves backward, Snowflake must pause ID generation until time catches up.

Here‚Äôs a **JavaScript implementation** of Twitter‚Äôs **Snowflake ID generator**:

### **JavaScript Implementation of Snowflake ID**

```javascript
class Snowflake {
    constructor(epoch = 1609459200000, machineId = 1) {
        this.epoch = epoch; // Custom epoch (e.g., 2021-01-01)
        this.machineId = machineId & 0x3FF; // 10-bit Machine ID (max 1023)
        this.sequence = 0; // 12-bit sequence number
        this.lastTimestamp = -1;
    }

    // Generate the next unique ID
    nextId() {
        let timestamp = Date.now();

        // If clock moves backward, wait until it catches up
        if (timestamp < this.lastTimestamp) {
            throw new Error("Clock moved backwards. Waiting...");
        }

        // If same millisecond, increment sequence
        if (timestamp === this.lastTimestamp) {
            this.sequence = (this.sequence + 1) & 0xFFF; // 12-bit sequence (0-4095)
            if (this.sequence === 0) {
                // Sequence overflow, wait for next millisecond
                while (timestamp <= this.lastTimestamp) {
                    timestamp = Date.now();
                }
            }
        } else {
            this.sequence = 0;
        }

        this.lastTimestamp = timestamp;

        // Construct the 64-bit ID
        return (
            ((BigInt(timestamp - this.epoch) << 22n) | // 41-bit timestamp
             (BigInt(this.machineId) << 12n) | // 10-bit machine ID
             BigInt(this.sequence)) // 12-bit sequence
        ).toString();
    }
}

// Example Usage
const snowflake = new Snowflake();
console.log(snowflake.nextId()); // Unique 64-bit ID
```

### **How It Works**
1. **Epoch (41 bits)** ‚Äì Uses a custom epoch (default: Jan 1, 2021) to reduce the timestamp size.
2. **Machine ID (10 bits)** ‚Äì Supports **up to 1024 unique nodes** generating IDs independently.
3. **Sequence Number (12 bits)** ‚Äì Allows **4096 unique IDs per millisecond per node**.
4. **Ensures Time Order** ‚Äì If the same millisecond, increments the sequence. If overflow, waits for the next millisecond.